
# Code quality
	black xml_extractor/                      # Code formatting
	mypy xml_extractor/                       # Type checking
	flake8 xml_extractor/                     # Linting


pytest tests/unit/test_contract_driven_truncation.py

python -m pytest tests/unit/test_validation_scenarios_unit.py
python -m pytest tests/unit/ -v --tb=short
python -m pytest tests/e2e/ -v

pytest tests/unit --maxfail=5 -v --tb=short

python .\tests\unit\test_contract_driven_truncation.py
python tests/e2e/test_pipeline_full_integration.py
python tests/run_comprehensive_suite.py

python -m pytest tests/ -q --tb=short


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

@workspace read .github/copilot.json

- You are a TDD, DDD, Clean Code Principles Python & SQL expert developer and architect. 
- We're working on a project together:
@workspace read README.md


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
TARGET: 11MM apps in 2 days = 3,820 apps/minute needed
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

BASELINE CHUNKING: ~2400
	- using defaults:  --workers 4 --batch-size 1000
	python run_production_processor.py --server "localhost\SQLEXPRESS" --database "XmlConversionDB" --chunk-size 100000 --app-id-start 1 --app-id-end 300000
	
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

PRODUCTION PERFORMANCE ORCHESTRATOR (CHUNKER) `run_production_processor.py`
restart processor every {n} records for performance with --chunk-size
supports running app_id ranges for easy segmentmentation with multiple instances (no SQL collisions)
recommend chunks ~100,000

	RANGE MODE - USE BIG CHUNKS
	# Processes any applications in range
	python run_production_processor.py --server "localhost\SQLEXPRESS" --database "XmlConversionDB" --chunk-size 100000 --app-id-start 1 --app-id-end 500000
	python run_production_processor.py --server "mbc-dev-npci-use1-db.cofvo8gypwe9.us-east-1.rds.amazonaws.com" --database "MACDEVOperational" --workers 4 --batch-size 1000 --app-id-start 1 --app-id-end 250000
	
	
DIRECT SINGLE-INSTANCE PROCESSING
For smaller runs using ranges or limits, filling in gaps in app_id ranges, and specific fixes/clean-up
	
	SEQUENTIAL LIMIT MODE
	python production_processor.py --server "mbc-dev-npci-use1-db.cofvo8gypwe9.us-east-1.rds.amazonaws.com" --database "MACDEVOperational" --enable-pooling --limit 13000
	python production_processor.py --server "localhost\SQLEXPRESS" --database "XmlConversionDB" --limit 2000
	
	- OR - 
	
	RANGE MODE
	python production_processor.py --server "localhost\SQLEXPRESS" --database "XmlConversionDB" --app-id-start 1900 --app-id-end 3000
	
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

TODO:
	- finish setting contract mappings for required and isnull
	- need mapping for app_operational_cc.sc_bank_account_type_num!!!
		locked_by_user

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

================================================================================
ANALYSIS & IMPACT
================================================================================

Per-Operation Latency:
  Connection establishment: 273.3 ms
  Simple query (reuse conn): 84.5 ms

Impact with 16 workers processing 2000 apps:

  Scenario 1: New connection per app
    Each worker: 125 apps × 273.3ms = 34.2s wasted on connections
    All 16 workers: 546.6s total wasted time

  Scenario 2: Reused connections, 50 queries per app
    Each worker: 125 apps × 50 queries × 84.5ms
    Each worker: 528.4s spent waiting for query responses
    All 16 workers: 8453.8s total wait time

  Performance Impact:
    ⚠️  HIGH LATENCY DETECTED (84.5ms per query)


TROUBLESHOOTING
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

--enable-pooling doesn't matter because it's already happening

~520 2020-12-02
python production_processor.py --server "mbc-dev-npci-use1-db.cofvo8gypwe9.us-east-1.rds.amazonaws.com" --database "MACDEVOperational" --log-level ERROR --workers 16 --limit 2000

# 10 instances ~4,900 apps/min
python launch_parallel_instances.py --server "mbc-dev-npci-use1-db.cofvo8gypwe9.us-east-1.rds.amazonaws.com" --database "MACDEVOperational" --log-level ERROR --instances 10 --workers 16 --limit 10000
